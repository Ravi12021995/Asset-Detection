{"cells":[{"cell_type":"code","source":["### 1. Mount Google Drive ###\n","\n","!fusermount -u /content/gdrive  # Unmount Google Drive\n","!rm -rf /content/gdrive         # Remove any existing files\n","from google.colab import drive\n","drive.mount('/content/gdrive')  # Remount Google Drive\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nhu_I1G218eF","executionInfo":{"status":"ok","timestamp":1743418199490,"user_tz":-330,"elapsed":17027,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"57d61dad-5945-4c2f-f45b-ec8fcd19e865"},"id":"Nhu_I1G218eF","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["fusermount: failed to unmount /content/gdrive: No such file or directory\n","Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["### 2. Define root directory ###\n","\n","ROOT_DIR = '/content/gdrive/MyDrive/REVA/Capstone 1/Dataset'"],"metadata":{"id":"pA36-SCE2zMe","executionInfo":{"status":"ok","timestamp":1743418205508,"user_tz":-330,"elapsed":74,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}}},"id":"pA36-SCE2zMe","execution_count":3,"outputs":[]},{"cell_type":"code","execution_count":4,"id":"7f86a1a2","metadata":{"execution":{"iopub.execute_input":"2025-02-27T13:38:59.121507Z","iopub.status.busy":"2025-02-27T13:38:59.121310Z","iopub.status.idle":"2025-02-27T13:39:05.054422Z","shell.execute_reply":"2025-02-27T13:39:05.053380Z"},"papermill":{"duration":5.937252,"end_time":"2025-02-27T13:39:05.055992","exception":false,"start_time":"2025-02-27T13:38:59.118740","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"7f86a1a2","executionInfo":{"status":"ok","timestamp":1743419308746,"user_tz":-330,"elapsed":1072104,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"5fcbf1e9-4ee0-4c8b-c4eb-8ad66e205906"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.99-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.99-py3-none-any.whl (976 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m976.9/976.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m794.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.99 ultralytics-thop-2.0.14\n"]}],"source":["### 3. Install Ultralytics ###\n","\n","!pip install ultralytics"]},{"cell_type":"markdown","source":["**1. YOLOv8**"],"metadata":{"id":"mGacsJ8h1TuH"},"id":"mGacsJ8h1TuH"},{"cell_type":"code","execution_count":null,"id":"7b6805ce","metadata":{"execution":{"iopub.execute_input":"2025-02-27T13:39:05.062822Z","iopub.status.busy":"2025-02-27T13:39:05.062573Z","iopub.status.idle":"2025-02-27T17:51:08.797755Z","shell.execute_reply":"2025-02-27T17:51:08.796723Z"},"papermill":{"duration":15123.740446,"end_time":"2025-02-27T17:51:08.799619","exception":false,"start_time":"2025-02-27T13:39:05.059173","status":"completed"},"tags":[],"id":"7b6805ce","outputId":"293f1ea0-41f2-4963-d377-38f323fadeb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 88.1MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Ultralytics 8.3.80 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/kaggle/input/yolo-yaml/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 755k/755k [00:00<00:00, 18.2MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Overriding model.yaml nc=80 with nc=4\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n","Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5.35M/5.35M [00:00<00:00, 76.0MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/railway-layout/train/labels... 4242 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4242/4242 [00:22<00:00, 185.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/railway-layout/train is not writeable, cache not saved.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/railway-layout/val/labels... 1636 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1636/1636 [00:07<00:00, 205.70it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/railway-layout/val is not writeable, cache not saved.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/50      2.28G      2.137       2.33      1.046         32        640: 100%|██████████| 266/266 [03:49<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.862      0.883      0.936      0.537\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/50      2.56G      1.496      1.097     0.8772         11        640: 100%|██████████| 266/266 [03:49<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296       0.92      0.946      0.975      0.609\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       3/50      2.79G      1.404     0.8799     0.8587         10        640: 100%|██████████| 266/266 [03:48<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296       0.96      0.945      0.981       0.64\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       4/50      2.71G      1.347     0.8036     0.8552         19        640: 100%|██████████| 266/266 [03:48<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.958      0.967      0.989      0.663\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       5/50       2.7G      1.266     0.7164      0.842         10        640: 100%|██████████| 266/266 [03:48<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296       0.98       0.98      0.991       0.66\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       6/50       2.6G      1.247     0.6883     0.8372         44        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296       0.97      0.976      0.991      0.671\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       7/50       2.7G      1.225     0.6663     0.8336         21        640: 100%|██████████| 266/266 [03:51<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.983      0.979      0.993      0.668\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       8/50       2.5G      1.181     0.6418     0.8292          8        640: 100%|██████████| 266/266 [03:48<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.982      0.992      0.994      0.716\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       9/50      2.74G      1.161     0.6261     0.8256         29        640: 100%|██████████| 266/266 [03:50<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.969      0.981      0.991      0.683\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      10/50      2.42G      1.135     0.6042     0.8265          2        640: 100%|██████████| 266/266 [03:50<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.958      0.964      0.987      0.657\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      11/50      2.68G      1.124     0.5966     0.8197         15        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.984      0.984      0.993      0.677\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      12/50      2.61G      1.109     0.5894     0.8213         42        640: 100%|██████████| 266/266 [03:49<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.988      0.995      0.995      0.733\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      13/50      2.38G      1.093     0.5749     0.8195         14        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.983      0.993      0.994       0.73\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      14/50      2.56G      1.083     0.5671     0.8167         36        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.987       0.99      0.994      0.756\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      15/50      2.59G      1.061     0.5525     0.8137         20        640: 100%|██████████| 266/266 [03:52<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.988      0.995      0.995      0.737\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      16/50      2.62G      1.045     0.5461     0.8113         13        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.986      0.995      0.995      0.757\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      17/50      2.74G      1.044     0.5435     0.8128          5        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.996      0.995      0.765\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      18/50      2.48G       1.04     0.5446     0.8093         27        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296       0.99      0.998      0.995      0.757\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      19/50      2.77G      1.012     0.5338     0.8106         12        640: 100%|██████████| 266/266 [03:49<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.991       0.99      0.995      0.758\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      20/50      2.57G      1.023     0.5378     0.8109         33        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:06<00:00,  1.28s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.998      0.995      0.766\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      21/50      2.47G     0.9936     0.5194     0.8084         32        640: 100%|██████████| 266/266 [03:48<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:06<00:00,  1.28s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.995      0.995      0.995      0.772\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      22/50      2.65G     0.9842     0.5128     0.8071         30        640: 100%|██████████| 266/266 [03:49<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.986      0.995      0.995      0.769\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      23/50      2.43G     0.9835     0.5143     0.8078         57        640: 100%|██████████| 266/266 [03:52<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.994      0.998      0.995      0.788\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      24/50      2.45G     0.9664     0.5048     0.8045         48        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.994      0.997      0.995      0.794\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      25/50      2.48G     0.9521     0.4944     0.8054         16        640: 100%|██████████| 266/266 [03:51<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.991      0.994      0.995      0.792\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      26/50       2.3G     0.9324     0.4864     0.8021         28        640: 100%|██████████| 266/266 [03:52<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.997      0.995      0.802\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      27/50       2.4G     0.9336     0.4851      0.804         19        640: 100%|██████████| 266/266 [03:51<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.997      0.995      0.805\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      28/50      2.58G     0.9134     0.4775     0.8013         19        640: 100%|██████████| 266/266 [03:51<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.999      0.995      0.802\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      29/50      2.59G     0.9044     0.4764     0.8009         56        640: 100%|██████████| 266/266 [03:53<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296       0.99      0.997      0.995      0.815\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      30/50      2.64G     0.9044     0.4732     0.7997         10        640: 100%|██████████| 266/266 [03:53<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:09<00:00,  1.33s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.994          1      0.995      0.813\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      31/50       2.7G     0.8879     0.4673     0.8004         10        640: 100%|██████████| 266/266 [03:53<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.998      0.995      0.825\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      32/50       2.7G     0.8794     0.4611     0.7986         18        640: 100%|██████████| 266/266 [03:54<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.996      0.995      0.822\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      33/50       2.5G     0.8687     0.4554      0.799          5        640: 100%|██████████| 266/266 [03:52<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.998      0.995      0.831\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      34/50      2.67G     0.8579     0.4482      0.798         14        640: 100%|██████████| 266/266 [03:54<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.994      0.998      0.995      0.838\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      35/50      2.29G     0.8537      0.449     0.7961         39        640: 100%|██████████| 266/266 [03:48<00:00,  1.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.29s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.995      0.998      0.995      0.836\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      36/50      2.38G     0.8391     0.4441     0.7977         13        640: 100%|██████████| 266/266 [03:53<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.997      0.997      0.995      0.842\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      37/50      2.63G     0.8356     0.4415      0.795          8        640: 100%|██████████| 266/266 [03:53<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.998      0.998      0.995      0.837\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      38/50       2.4G     0.8255     0.4374     0.7955         20        640: 100%|██████████| 266/266 [03:51<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.995      0.998      0.995      0.845\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      39/50      2.34G     0.8103     0.4313     0.7962          8        640: 100%|██████████| 266/266 [03:56<00:00,  1.12it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.998      0.995      0.842\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      40/50      2.57G     0.7978     0.4241     0.7952         20        640: 100%|██████████| 266/266 [03:55<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.995      0.999      0.995      0.846\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      41/50      2.08G     0.7213     0.3936     0.7893          5        640: 100%|██████████| 266/266 [03:56<00:00,  1.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.995      0.999      0.995      0.845\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      42/50      2.13G      0.698     0.3881     0.7884         15        640: 100%|██████████| 266/266 [03:46<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.996      0.997      0.995      0.858\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      43/50      2.13G     0.6876     0.3824     0.7879          9        640: 100%|██████████| 266/266 [03:51<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.996      0.995       0.86\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      44/50      2.07G     0.6731     0.3753     0.7879         17        640: 100%|██████████| 266/266 [03:51<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.32s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.994      0.995      0.859\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      45/50      2.12G      0.655     0.3703     0.7853         10        640: 100%|██████████| 266/266 [03:50<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:07<00:00,  1.30s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.994      0.996      0.995      0.867\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      46/50      2.08G     0.6386     0.3598     0.7879          3        640: 100%|██████████| 266/266 [03:47<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.998      0.995      0.869\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      47/50      2.12G     0.6268     0.3569     0.7854         12        640: 100%|██████████| 266/266 [03:25<00:00,  1.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.999      0.995       0.87\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      48/50      2.06G      0.611     0.3507     0.7818          8        640: 100%|██████████| 266/266 [03:47<00:00,  1.17it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:09<00:00,  1.34s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.993      0.998      0.995      0.875\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      49/50      2.12G     0.6067     0.3494      0.785         17        640: 100%|██████████| 266/266 [03:53<00:00,  1.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.997      0.995      0.874\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["      50/50      2.07G     0.5905     0.3401     0.7825          7        640: 100%|██████████| 266/266 [03:52<00:00,  1.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:08<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.998      0.995      0.878\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","50 epochs completed in 4.161 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics 8.3.80 🚀 Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"name":"stderr","output_type":"stream","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 52/52 [01:12<00:00,  1.39s/it]\n"]},{"name":"stdout","output_type":"stream","text":["                   all       1636      10296      0.992      0.998      0.995      0.878\n","                Switch        848       3357      0.993          1      0.995      0.825\n","              Crossing       1307       2894      0.991      0.997      0.995      0.903\n","         Normal Signal        519       3190      0.986          1      0.995      0.876\n","            B2B Signal        413        855          1      0.995      0.995       0.91\n","Speed: 0.2ms preprocess, 2.1ms inference, 0.0ms loss, 1.0ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n"]}],"source":["### 4. Train model ###\n","\n","import os\n","\n","from ultralytics import YOLO\n","\n","\n","# Load a model\n","model = YOLO(\"yolov8n.pt\")  # load pre trained model\n","\n","# Use the model\n","results = model.train(data=os.path.join(ROOT_DIR, \"data.yaml\"), epochs=50)"]},{"cell_type":"code","source":["### 5. Copy results ###\n","\n","!scp -r /content/runs '/content/gdrive/MyDrive/REVA/Capstone 1/Result'"],"metadata":{"id":"SBOWh5cy29Zu"},"id":"SBOWh5cy29Zu","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"0f480a65","metadata":{"execution":{"iopub.execute_input":"2025-02-27T17:51:11.670340Z","iopub.status.busy":"2025-02-27T17:51:11.669954Z","iopub.status.idle":"2025-02-27T17:51:11.714309Z","shell.execute_reply":"2025-02-27T17:51:11.713622Z"},"papermill":{"duration":1.408347,"end_time":"2025-02-27T17:51:11.715650","exception":false,"start_time":"2025-02-27T17:51:10.307303","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"0f480a65","executionInfo":{"status":"ok","timestamp":1742036002865,"user_tz":-330,"elapsed":10110,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"30157ba4-3751-4d54-8bb0-8b828d933d50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}],"source":["from ultralytics import YOLO\n","\n","# Load the trained model\n","model = YOLO('/content/gdrive/MyDrive/REVA/Capstone 1/Result/runs/detect/train/weights/best.pt')"]},{"cell_type":"code","execution_count":null,"id":"c2c02529","metadata":{"execution":{"iopub.execute_input":"2025-02-27T17:51:14.618064Z","iopub.status.busy":"2025-02-27T17:51:14.617747Z","iopub.status.idle":"2025-02-27T17:51:48.321389Z","shell.execute_reply":"2025-02-27T17:51:48.320540Z"},"papermill":{"duration":35.163552,"end_time":"2025-02-27T17:51:48.322708","exception":false,"start_time":"2025-02-27T17:51:13.159156","status":"completed"},"tags":[],"colab":{"base_uri":"https://localhost:8080/"},"id":"c2c02529","executionInfo":{"status":"ok","timestamp":1742036115536,"user_tz":-330,"elapsed":107547,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"17d175f4-ee0d-484c-d984-b154daffa221"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0001_aug_29.jpg: 416x640 2 Normal Signals, 2 B2B Signals, 341.5ms\n","image 2/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0001_aug_30.jpg: 416x640 2 Normal Signals, 2 B2B Signals, 720.4ms\n","image 3/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0002_aug_17.jpg: 416x640 6 Normal Signals, 3 B2B Signals, 176.7ms\n","image 4/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0008_aug_1.jpg: 416x640 12 Switchs, 4 Normal Signals, 147.0ms\n","image 5/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0009_aug_1.jpg: 416x640 12 Switchs, 3 Normal Signals, 144.9ms\n","image 6/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0009_aug_17.jpg: 416x640 12 Switchs, 3 Normal Signals, 149.2ms\n","image 7/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0009_aug_27.jpg: 416x640 12 Switchs, 3 Normal Signals, 212.7ms\n","image 8/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0009_aug_6.jpg: 416x640 12 Switchs, 3 Normal Signals, 284.6ms\n","image 9/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Combined_page-0009_aug_9.jpg: 416x640 12 Switchs, 3 Normal Signals, 222.6ms\n","image 10/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0004_aug_23.jpg: 416x640 1 Switch, 1 Crossing, 223.9ms\n","image 11/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0005_aug_22.jpg: 416x640 2 Crossings, 223.3ms\n","image 12/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0005_aug_3.jpg: 416x640 2 Crossings, 222.4ms\n","image 13/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0007_aug_1.jpg: 416x640 2 Crossings, 219.4ms\n","image 14/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0008_aug_20.jpg: 416x640 3 Switchs, 1 Crossing, 4 Normal Signals, 202.2ms\n","image 15/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0010_aug_15.jpg: 416x640 1 Crossing, 2 B2B Signals, 204.6ms\n","image 16/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0010_aug_6.jpg: 416x640 1 Crossing, 2 B2B Signals, 133.7ms\n","image 17/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0015_aug_26.jpg: 416x640 1 Switch, 1 Crossing, 186.3ms\n","image 18/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0016_aug_13.jpg: 416x640 1 Switch, 1 Crossing, 2 B2B Signals, 146.8ms\n","image 19/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0016_aug_19.jpg: 416x640 1 Switch, 1 Crossing, 2 B2B Signals, 160.0ms\n","image 20/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0016_aug_27.jpg: 416x640 1 Switch, 1 Crossing, 2 B2B Signals, 135.9ms\n","image 21/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0016_aug_3.jpg: 416x640 1 Switch, 1 Crossing, 2 B2B Signals, 136.1ms\n","image 22/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0018_aug_21.jpg: 416x640 2 Crossings, 2 B2B Signals, 143.1ms\n","image 23/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0019_aug_7.jpg: 416x640 1 Switch, 142.5ms\n","image 24/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0020_aug_22.jpg: 416x640 5 Switchs, 2 Crossings, 4 Normal Signals, 140.1ms\n","image 25/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0022_aug_27.jpg: 416x640 6 Crossings, 148.5ms\n","image 26/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0025_aug_21.jpg: 416x640 2 Crossings, 2 B2B Signals, 133.0ms\n","image 27/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0026_aug_27.jpg: 416x640 1 Crossing, 150.8ms\n","image 28/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0027_aug_16.jpg: 416x640 1 Crossing, 216.1ms\n","image 29/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0027_aug_17.jpg: 416x640 1 Crossing, 289.8ms\n","image 30/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0028_aug_20.jpg: 416x640 3 Switchs, 4 Normal Signals, 383.2ms\n","image 31/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0029_aug_1.jpg: 416x640 1 Crossing, 152.8ms\n","image 32/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0029_aug_2.jpg: 416x640 1 Crossing, 134.4ms\n","image 33/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0031_aug_23.jpg: 416x640 1 Switch, 3 Crossings, 2 B2B Signals, 150.7ms\n","image 34/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0032_aug_14.jpg: 416x640 4 Switchs, 3 Normal Signals, 153.6ms\n","image 35/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0035_aug_16.jpg: 416x640 2 Switchs, 1 Crossing, 2 B2B Signals, 222.2ms\n","image 36/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0036_aug_6.jpg: 416x640 2 Crossings, 220.9ms\n","image 37/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0037_aug_18.jpg: 416x640 1 Switch, 1 Crossing, 2 B2B Signals, 221.5ms\n","image 38/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0039_aug_18.jpg: 416x640 4 Switchs, 1 Crossing, 3 Normal Signals, 233.0ms\n","image 39/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0039_aug_3.jpg: 416x640 4 Switchs, 1 Crossing, 3 Normal Signals, 219.0ms\n","image 40/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0040_aug_15.jpg: 416x640 1 Crossing, 219.7ms\n","image 41/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0040_aug_4.jpg: 416x640 1 Crossing, 300.1ms\n","image 42/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0041_aug_11.jpg: 416x640 2 B2B Signals, 290.7ms\n","image 43/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0041_aug_24.jpg: 416x640 2 B2B Signals, 378.9ms\n","image 44/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0042_aug_15.jpg: 416x640 2 Switchs, 2 Crossings, 247.9ms\n","image 45/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0042_aug_25.jpg: 416x640 2 Switchs, 2 Crossings, 136.4ms\n","image 46/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0043_aug_13.jpg: 416x640 1 Crossing, 2 B2B Signals, 169.3ms\n","image 47/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0043_aug_14.jpg: 416x640 1 Crossing, 2 B2B Signals, 149.3ms\n","image 48/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0043_aug_3.jpg: 416x640 1 Crossing, 2 B2B Signals, 139.5ms\n","image 49/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0044_aug_19.jpg: 416x640 2 Crossings, 136.6ms\n","image 50/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0044_aug_25.jpg: 416x640 2 Crossings, 156.4ms\n","image 51/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0045_aug_13.jpg: 416x640 1 Crossing, 2 B2B Signals, 146.4ms\n","image 52/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0045_aug_27.jpg: 416x640 1 Crossing, 2 B2B Signals, 134.9ms\n","image 53/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0046_aug_11.jpg: 416x640 1 Crossing, 185.6ms\n","image 54/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0046_aug_27.jpg: 416x640 1 Crossing, 165.7ms\n","image 55/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0048_aug_27.jpg: 416x640 1 Switch, 1 Crossing, 147.8ms\n","image 56/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0049_aug_13.jpg: 416x640 4 Switchs, 1 Crossing, 4 Normal Signals, 138.6ms\n","image 57/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0049_aug_30.jpg: 416x640 4 Switchs, 1 Crossing, 4 Normal Signals, 186.0ms\n","image 58/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0050_aug_7.jpg: 416x640 1 Switch, 1 Crossing, 216.1ms\n","image 59/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0051_aug_10.jpg: 416x640 2 Crossings, 2 B2B Signals, 229.2ms\n","image 60/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0051_aug_4.jpg: 416x640 2 Crossings, 2 B2B Signals, 230.0ms\n","image 61/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0051_aug_9.jpg: 416x640 2 Crossings, 2 B2B Signals, 218.9ms\n","image 62/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0053_aug_9.jpg: 416x640 5 Switchs, 2 Crossings, 4 Normal Signals, 239.9ms\n","image 63/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0056_aug_11.jpg: 416x640 2 Crossings, 217.0ms\n","image 64/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0056_aug_18.jpg: 416x640 2 Crossings, 179.7ms\n","image 65/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0057_aug_22.jpg: 416x640 2 Crossings, 2 B2B Signals, 195.9ms\n","image 66/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0058_aug_19.jpg: 416x640 1 Crossing, 172.8ms\n","image 67/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0058_aug_21.jpg: 416x640 1 Crossing, 139.2ms\n","image 68/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0059_aug_5.jpg: 416x640 1 Crossing, 147.7ms\n","image 69/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0063_aug_23.jpg: 416x640 2 Crossings, 2 B2B Signals, 152.7ms\n","image 70/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0067_aug_18.jpg: 416x640 3 Crossings, 154.6ms\n","image 71/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0067_aug_3.jpg: 416x640 3 Crossings, 143.4ms\n","image 72/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0070_aug_16.jpg: 416x640 2 Switchs, 142.1ms\n","image 73/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0077_aug_17.jpg: 416x640 2 B2B Signals, 144.1ms\n","image 74/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0077_aug_25.jpg: 416x640 2 B2B Signals, 140.0ms\n","image 75/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0080_aug_30.jpg: 416x640 1 Crossing, 154.6ms\n","image 76/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0080_aug_5.jpg: 416x640 1 Crossing, 172.5ms\n","image 77/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0081_aug_23.jpg: 416x640 1 Crossing, 150.8ms\n","image 78/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0082_aug_1.jpg: 416x640 2 B2B Signals, 135.8ms\n","image 79/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0082_aug_18.jpg: 416x640 2 B2B Signals, 147.8ms\n","image 80/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0083_aug_14.jpg: 416x640 2 Crossings, 139.4ms\n","image 81/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0083_aug_20.jpg: 416x640 2 Crossings, 138.4ms\n","image 82/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0083_aug_4.jpg: 416x640 2 Crossings, 154.6ms\n","image 83/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0084_aug_8.jpg: 416x640 2 Crossings, 139.0ms\n","image 84/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0085_aug_1.jpg: 416x640 4 Switchs, 1 Crossing, 4 Normal Signals, 136.1ms\n","image 85/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0086_aug_12.jpg: 416x640 1 Switch, 148.2ms\n","image 86/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0087_aug_19.jpg: 416x640 1 Switch, 1 Crossing, 258.6ms\n","image 87/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0087_aug_26.jpg: 416x640 1 Switch, 1 Crossing, 213.3ms\n","image 88/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0090_aug_1.jpg: 416x640 2 Crossings, 2 Normal Signals, 229.5ms\n","image 89/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0093_aug_3.jpg: 416x640 1 Switch, 221.1ms\n","image 90/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0094_aug_4.jpg: 416x640 1 Switch, 3 Crossings, 1 B2B Signal, 246.5ms\n","image 91/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0094_aug_9.jpg: 416x640 1 Switch, 3 Crossings, 2 B2B Signals, 243.4ms\n","image 92/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0095_aug_14.jpg: 416x640 1 Crossing, 166.5ms\n","image 93/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0096_aug_28.jpg: 416x640 4 Switchs, 1 Crossing, 4 Normal Signals, 171.9ms\n","image 94/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0098_aug_26.jpg: 416x640 1 Crossing, 198.6ms\n","image 95/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0107_aug_7.jpg: 416x640 1 Switch, 2 B2B Signals, 138.2ms\n","image 96/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0109_aug_20.jpg: 416x640 1 Switch, 1 Crossing, 143.2ms\n","image 97/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0112_aug_15.jpg: 416x640 1 Crossing, 2 B2B Signals, 138.3ms\n","image 98/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0115_aug_14.jpg: 416x640 1 Crossing, 145.6ms\n","image 99/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0116_aug_27.jpg: 416x640 1 Crossing, 139.9ms\n","image 100/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0117_aug_10.jpg: 416x640 1 Crossing, 2 B2B Signals, 166.3ms\n","image 101/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0117_aug_23.jpg: 416x640 1 Crossing, 2 B2B Signals, 138.6ms\n","image 102/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0119_aug_20.jpg: 416x640 1 Crossing, 2 B2B Signals, 163.4ms\n","image 103/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0120_aug_30.jpg: 416x640 2 Crossings, 135.3ms\n","image 104/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0121_aug_13.jpg: 416x640 7 Switchs, 2 Crossings, 3 Normal Signals, 137.7ms\n","image 105/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0122_aug_24.jpg: 416x640 1 Crossing, 200.6ms\n","image 106/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0124_aug_10.jpg: 416x640 2 Crossings, 138.1ms\n","image 107/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0124_aug_11.jpg: 416x640 2 Crossings, 134.9ms\n","image 108/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0125_aug_2.jpg: 416x640 15 Switchs, 5 Crossings, 9 Normal Signals, 146.3ms\n","image 109/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0128_aug_19.jpg: 416x640 7 Crossings, 136.9ms\n","image 110/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0129_aug_20.jpg: 416x640 6 Crossings, 2 B2B Signals, 148.1ms\n","image 111/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0129_aug_26.jpg: 416x640 6 Crossings, 2 B2B Signals, 139.2ms\n","image 112/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0131_aug_19.jpg: 416x640 3 Switchs, 3 Crossings, 4 Normal Signals, 142.7ms\n","image 113/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0131_aug_20.jpg: 416x640 3 Switchs, 3 Crossings, 4 Normal Signals, 212.4ms\n","image 114/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0133_aug_10.jpg: 416x640 5 Crossings, 2 B2B Signals, 238.7ms\n","image 115/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0133_aug_2.jpg: 416x640 5 Crossings, 2 B2B Signals, 274.9ms\n","image 116/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0136_aug_16.jpg: 416x640 4 Crossings, 208.9ms\n","image 117/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0136_aug_9.jpg: 416x640 4 Crossings, 241.5ms\n","image 118/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0137_aug_29.jpg: 416x640 1 Crossing, 2 B2B Signals, 229.9ms\n","image 119/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0138_aug_10.jpg: 416x640 4 Switchs, 2 Crossings, 4 Normal Signals, 197.3ms\n","image 120/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0139_aug_15.jpg: 416x640 3 Crossings, 191.2ms\n","image 121/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0143_aug_9.jpg: 416x640 2 Crossings, 145.8ms\n","image 122/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0145_aug_19.jpg: 416x640 3 Crossings, 136.8ms\n","image 123/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0147_aug_21.jpg: 416x640 3 Switchs, 2 Crossings, 4 Normal Signals, 175.8ms\n","image 124/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0148_aug_29.jpg: 416x640 1 Switch, 133.3ms\n","image 125/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0150_aug_19.jpg: 416x640 2 Crossings, 138.7ms\n","image 126/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0150_aug_30.jpg: 416x640 2 Crossings, 141.9ms\n","image 127/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0154_aug_19.jpg: 416x640 4 Switchs, 3 Crossings, 4 Normal Signals, 139.6ms\n","image 128/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0155_aug_17.jpg: 416x640 2 Crossings, 163.4ms\n","image 129/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0156_aug_7.jpg: 416x640 2 B2B Signals, 161.1ms\n","image 130/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0157_aug_3.jpg: 416x640 2 Switchs, 2 Crossings, 136.9ms\n","image 131/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0158_aug_6.jpg: 416x640 1 Switch, 2 Crossings, 2 B2B Signals, 146.5ms\n","image 132/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0159_aug_14.jpg: 416x640 1 Switch, 1 Crossing, 137.9ms\n","image 133/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0159_aug_20.jpg: 416x640 1 Switch, 1 Crossing, 150.1ms\n","image 134/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0159_aug_21.jpg: 416x640 1 Switch, 1 Crossing, 136.4ms\n","image 135/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0163_aug_25.jpg: 416x640 2 Crossings, 2 B2B Signals, 141.2ms\n","image 136/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0164_aug_2.jpg: 416x640 2 Crossings, 150.1ms\n","image 137/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0165_aug_30.jpg: 416x640 4 Crossings, 2 B2B Signals, 160.3ms\n","image 138/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0166_aug_29.jpg: 416x640 3 Crossings, 148.6ms\n","image 139/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0168_aug_17.jpg: 416x640 4 Crossings, 146.9ms\n","image 140/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0168_aug_19.jpg: 416x640 4 Crossings, 228.2ms\n","image 141/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0169_aug_18.jpg: 416x640 1 Switch, 7 Crossings, 5 Normal Signals, 1 B2B Signal, 240.5ms\n","image 142/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0169_aug_2.jpg: 416x640 1 Switch, 7 Crossings, 5 Normal Signals, 1 B2B Signal, 228.8ms\n","image 143/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0171_aug_20.jpg: 416x640 12 Switchs, 2 Crossings, 8 Normal Signals, 221.4ms\n","image 144/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0172_aug_3.jpg: 416x640 6 Switchs, 263.2ms\n","image 145/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0173_aug_11.jpg: 416x640 2 Switchs, 3 Crossings, 234.8ms\n","image 146/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0175_aug_4.jpg: 416x640 3 Crossings, 2 B2B Signals, 143.3ms\n","image 147/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0176_aug_19.jpg: 416x640 6 Crossings, 136.2ms\n","image 148/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0177_aug_13.jpg: 416x640 3 Crossings, 2 B2B Signals, 210.2ms\n","image 149/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0179_aug_29.jpg: 416x640 1 Crossing, 145.3ms\n","image 150/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0180_aug_1.jpg: 416x640 7 Switchs, 1 Crossing, 8 Normal Signals, 154.8ms\n","image 151/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0180_aug_13.jpg: 416x640 7 Switchs, 1 Crossing, 8 Normal Signals, 140.4ms\n","image 152/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0182_aug_22.jpg: 416x640 4 Switchs, 2 Crossings, 4 Normal Signals, 155.0ms\n","image 153/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0183_aug_28.jpg: 416x640 2 Crossings, 143.7ms\n","image 154/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0186_aug_16.jpg: 416x640 1 Crossing, 139.3ms\n","image 155/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0186_aug_25.jpg: 416x640 1 Crossing, 152.6ms\n","image 156/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0187_aug_15.jpg: 416x640 3 Crossings, 151.6ms\n","image 157/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0189_aug_21.jpg: 416x640 1 Switch, 1 Crossing, 3 Normal Signals, 137.3ms\n","image 158/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0189_aug_26.jpg: 416x640 1 Switch, 1 Crossing, 3 Normal Signals, 147.3ms\n","image 159/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0189_aug_7.jpg: 416x640 1 Switch, 1 Crossing, 3 Normal Signals, 167.6ms\n","image 160/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0191_aug_17.jpg: 416x640 5 Crossings, 1 B2B Signal, 140.5ms\n","image 161/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0191_aug_7.jpg: 416x640 5 Crossings, 1 B2B Signal, 160.2ms\n","image 162/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0193_aug_7.jpg: 416x640 1 Crossing, 140.6ms\n","image 163/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0196_aug_11.jpg: 416x640 2 Switchs, 6 Normal Signals, 153.4ms\n","image 164/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0197_aug_30.jpg: 416x640 8 Switchs, 8 Normal Signals, 164.7ms\n","image 165/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0197_aug_5.jpg: 416x640 8 Switchs, 8 Normal Signals, 157.0ms\n","image 166/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0198_aug_9.jpg: 416x640 8 Switchs, 8 Normal Signals, 143.8ms\n","image 167/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0199_aug_29.jpg: 416x640 2 Switchs, 6 Normal Signals, 233.3ms\n","image 168/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0200_aug_13.jpg: 416x640 2 Switchs, 6 Normal Signals, 215.0ms\n","image 169/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0200_aug_14.jpg: 416x640 2 Switchs, 6 Normal Signals, 228.3ms\n","image 170/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0200_aug_6.jpg: 416x640 2 Switchs, 6 Normal Signals, 254.5ms\n","image 171/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0201_aug_30.jpg: 416x640 2 Switchs, 2 Crossings, 6 Normal Signals, 236.4ms\n","image 172/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0205_aug_19.jpg: 416x640 16 Switchs, 16 Normal Signals, 233.6ms\n","image 173/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0205_aug_20.jpg: 416x640 16 Switchs, 16 Normal Signals, 139.9ms\n","image 174/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0206_aug_2.jpg: 416x640 8 Switchs, 8 Normal Signals, 192.0ms\n","image 175/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0206_aug_5.jpg: 416x640 8 Switchs, 8 Normal Signals, 148.1ms\n","image 176/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0207_aug_10.jpg: 416x640 9 Switchs, 14 Normal Signals, 143.2ms\n","image 177/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0208_aug_18.jpg: 416x640 9 Switchs, 14 Normal Signals, 143.9ms\n","image 178/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0208_aug_26.jpg: 416x640 8 Switchs, 14 Normal Signals, 144.3ms\n","image 179/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0208_aug_8.jpg: 416x640 8 Switchs, 14 Normal Signals, 152.7ms\n","image 180/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0209_aug_14.jpg: 416x640 10 Switchs, 2 Crossings, 14 Normal Signals, 135.2ms\n","image 181/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0210_aug_16.jpg: 416x640 10 Switchs, 2 Crossings, 14 Normal Signals, 145.3ms\n","image 182/182 /content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images/Layout_01-25-25_page-0210_aug_5.jpg: 416x640 10 Switchs, 2 Crossings, 14 Normal Signals, 136.2ms\n","Speed: 5.2ms preprocess, 180.3ms inference, 1.4ms postprocess per image at shape (1, 3, 416, 640)\n","Results saved to \u001b[1m/content/gdrive/MyDrive/REVA/Capstone 1/TestAnnotation50/test_predictions\u001b[0m\n","182 labels saved to /content/gdrive/MyDrive/REVA/Capstone 1/TestAnnotation50/test_predictions/labels\n"]}],"source":["# Define the path to your test images\n","test_images_path = '/content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/images'\n","\n","# Run inference\n","results = model.predict(\n","    source=test_images_path,\n","    save=True,  # Save output images with annotations\n","    save_txt=True,  # Save detection results in .txt format\n","    project='/content/gdrive/MyDrive/REVA/Capstone 1/TestAnnotation50',  # Directory to save results\n","    name='test_predictions',  # Subdirectory name for this run\n","    conf=0.50  # Confidence threshold for detections\n",")"]},{"cell_type":"code","execution_count":null,"id":"7e2bbcb9","metadata":{"execution":{"iopub.execute_input":"2025-02-27T17:51:51.256615Z","iopub.status.busy":"2025-02-27T17:51:51.256320Z","iopub.status.idle":"2025-02-27T17:51:51.259665Z","shell.execute_reply":"2025-02-27T17:51:51.258997Z"},"papermill":{"duration":1.495945,"end_time":"2025-02-27T17:51:51.260862","exception":false,"start_time":"2025-02-27T17:51:49.764917","status":"completed"},"tags":[],"id":"7e2bbcb9"},"outputs":[],"source":["import numpy as np\n","import os"]},{"cell_type":"code","source":["import os\n","import json\n","import numpy as np\n","from collections import defaultdict\n","\n","# IoU Calculation Function\n","def calculate_iou(box1, box2):\n","    \"\"\"Calculate IoU between two bounding boxes.\"\"\"\n","    x1 = max(box1[0], box2[0])\n","    y1 = max(box1[1], box2[1])\n","    x2 = min(box1[0] + box1[2], box2[0] + box2[2])\n","    y2 = min(box1[1] + box1[3], box2[1] + box2[3])\n","\n","    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n","    area_box1 = box1[2] * box1[3]\n","    area_box2 = box2[2] * box2[3]\n","    union = area_box1 + area_box2 - intersection\n","\n","    return intersection / union if union > 0 else 0\n","\n","# YOLO Label File Parsing\n","def parse_yolo_file(file_path):\n","    \"\"\"Parse a YOLO-format file and return a list of bounding boxes.\"\"\"\n","    boxes = []\n","    with open(file_path, \"r\") as f:\n","        for line in f:\n","            values = line.strip().split()\n","            if len(values) < 5:\n","                continue\n","            class_id = int(values[0])\n","            x, y, width, height = map(float, values[1:5])\n","            boxes.append({\"class_id\": class_id, \"bbox\": [x, y, width, height]})\n","    return boxes\n","\n","# Model Evaluation Across Multiple IoU Thresholds\n","def evaluate(gt_dir, pred_dir, iou_thresholds=[0.4, 0.5, 0.6, 0.7, 0.75], num_classes=4):\n","    \"\"\"Evaluate predictions against ground truth across multiple IoU thresholds.\"\"\"\n","\n","    gt_files = sorted(os.listdir(gt_dir))\n","    pred_files = sorted(os.listdir(pred_dir))\n","\n","    if len(gt_files) != len(pred_files):\n","        print(f\"Warning: Mismatch between number of ground truth files ({len(gt_files)}) and prediction files ({len(pred_files)})\")\n","\n","    results = {}\n","\n","    for iou_threshold in iou_thresholds:\n","        confusion_matrix = np.zeros((num_classes + 1, num_classes), dtype=int)\n","\n","        for gt_file, pred_file in zip(gt_files, pred_files):\n","            gt_path = os.path.join(gt_dir, gt_file)\n","            pred_path = os.path.join(pred_dir, pred_file)\n","\n","            if not os.path.exists(gt_path):\n","                print(f\"Warning: Ground truth file '{gt_file}' not found.\")\n","                continue\n","\n","            if not os.path.exists(pred_path):\n","                print(f\"Warning: Prediction file '{pred_file}' not found.\")\n","                continue\n","\n","            gt_boxes = parse_yolo_file(gt_path)\n","            pred_boxes = parse_yolo_file(pred_path)\n","\n","            for pred_box in pred_boxes:\n","                pred_class = pred_box[\"class_id\"]\n","                pred_coords = pred_box[\"bbox\"]\n","                matched = False\n","\n","                for gt_box in gt_boxes:\n","                    gt_class = gt_box[\"class_id\"]\n","                    gt_coords = gt_box[\"bbox\"]\n","\n","                    if gt_class == pred_class and calculate_iou(pred_coords, gt_coords) > iou_threshold:\n","                        confusion_matrix[gt_class][pred_class] += 1\n","                        matched = True\n","                        break\n","\n","                if not matched:\n","                    confusion_matrix[num_classes][pred_class] += 1\n","\n","        # Compute Precision, Recall, and F1-score\n","        precision, recall, f1_score = [], [], []\n","\n","        for i in range(num_classes):\n","            tp = confusion_matrix[i][i]\n","            fp = sum(confusion_matrix[:, i]) - tp\n","            fn = sum(confusion_matrix[i, :]) - tp\n","\n","            p = tp / (tp + fp) if tp + fp > 0 else 0\n","            r = tp / (tp + fn) if tp + fn > 0 else 0\n","            f1 = (2 * p * r) / (p + r) if p + r > 0 else 0\n","\n","            precision.append(p)\n","            recall.append(r)\n","            f1_score.append(f1)\n","\n","        # Compute mAP\n","        mAP = np.mean(precision) if precision else 0\n","\n","        results[iou_threshold] = {\n","            \"Precision\": precision,\n","            \"Recall\": recall,\n","            \"F1-score\": f1_score,\n","            \"mAP\": round(mAP, 4)\n","        }\n","\n","    # Print Results\n","    for iou_thresh, metrics in results.items():\n","        print(f\"\\nResults at IoU {iou_thresh}:\")\n","        print(f\"mAP: {metrics['mAP']:.4f}\")\n","        for class_id in range(num_classes):\n","            print(f\"Class {class_id + 1}: Precision={metrics['Precision'][class_id]:.3f}, \"\n","                  f\"Recall={metrics['Recall'][class_id]:.3f}, \"\n","                  f\"F1-score={metrics['F1-score'][class_id]:.3f}\")\n","\n","    return results\n","\n","# Example Usage\n","gt_dir = \"/content/gdrive/MyDrive/REVA/Capstone 1/Dataset/test/labels\"\n","pred_dir = \"/content/gdrive/MyDrive/REVA/Capstone 1/TestAnnotation50/test_predictions/labels\"\n","num_classes = 4\n","iou_thresholds = [0.4, 0.5, 0.6, 0.7, 0.75]\n","\n","evaluate(gt_dir, pred_dir, iou_thresholds, num_classes)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5mNagZt1lEfN","executionInfo":{"status":"ok","timestamp":1742206376361,"user_tz":-330,"elapsed":32032,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"5338fe17-87fe-4180-af1b-55330578d92a"},"id":"5mNagZt1lEfN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Results at IoU 0.4:\n","mAP: 0.9860\n","Class 1: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 2: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 3: Precision=0.944, Recall=1.000, F1-score=0.971\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.5:\n","mAP: 0.9760\n","Class 1: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 2: Precision=0.997, Recall=1.000, F1-score=0.998\n","Class 3: Precision=0.908, Recall=1.000, F1-score=0.952\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.6:\n","mAP: 0.9523\n","Class 1: Precision=0.995, Recall=1.000, F1-score=0.997\n","Class 2: Precision=0.997, Recall=1.000, F1-score=0.998\n","Class 3: Precision=0.818, Recall=1.000, F1-score=0.900\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.7:\n","mAP: 0.9187\n","Class 1: Precision=0.942, Recall=1.000, F1-score=0.970\n","Class 2: Precision=0.993, Recall=1.000, F1-score=0.997\n","Class 3: Precision=0.739, Recall=1.000, F1-score=0.850\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.75:\n","mAP: 0.8572\n","Class 1: Precision=0.845, Recall=1.000, F1-score=0.916\n","Class 2: Precision=0.938, Recall=1.000, F1-score=0.968\n","Class 3: Precision=0.686, Recall=1.000, F1-score=0.814\n","Class 4: Precision=0.960, Recall=1.000, F1-score=0.980\n"]},{"output_type":"execute_result","data":{"text/plain":["{0.4: {'Precision': [1.0, 1.0, 0.9439775910364145, 1.0],\n","  'Recall': [1.0, 1.0, 1.0, 1.0],\n","  'F1-score': [1.0, 1.0, 0.9711815561959654, 1.0],\n","  'mAP': 0.986},\n"," 0.5: {'Precision': [1.0, 0.9965397923875432, 0.907563025210084, 1.0],\n","  'Recall': [1.0, 1.0, 1.0, 1.0],\n","  'F1-score': [1.0, 0.9982668977469671, 0.9515418502202644, 1.0],\n","  'mAP': 0.976},\n"," 0.6: {'Precision': [0.9947368421052631,\n","   0.9965397923875432,\n","   0.8179271708683473,\n","   1.0],\n","  'Recall': [1.0, 1.0, 1.0, 1.0],\n","  'F1-score': [0.9973614775725593,\n","   0.9982668977469671,\n","   0.8998459167950693,\n","   1.0],\n","  'mAP': 0.9523},\n"," 0.7: {'Precision': [0.9421052631578948,\n","   0.9930795847750865,\n","   0.7394957983193278,\n","   1.0],\n","  'Recall': [1.0, 1.0, 1.0, 1.0],\n","  'F1-score': [0.970189701897019, 0.9965277777777778, 0.8502415458937198, 1.0],\n","  'mAP': 0.9187},\n"," 0.75: {'Precision': [0.8447368421052631,\n","   0.9377162629757786,\n","   0.6862745098039216,\n","   0.96],\n","  'Recall': [1.0, 1.0, 1.0, 1.0],\n","  'F1-score': [0.9158345221112697,\n","   0.967857142857143,\n","   0.813953488372093,\n","   0.9795918367346939],\n","  'mAP': 0.8572}}"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["**2. Faster RCNN**"],"metadata":{"id":"Bnlclz66gZwN"},"id":"Bnlclz66gZwN"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m2vQ8Q5nwKxi","executionInfo":{"status":"ok","timestamp":1742193979142,"user_tz":-330,"elapsed":33767,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"42da7b43-1ed5-42ad-b5d4-bda8f111f6b4"},"id":"m2vQ8Q5nwKxi","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["import torch\n","import torchvision\n","from torch.utils.data import DataLoader\n","from torchvision.models.detection import FasterRCNN\n","from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as F\n","import matplotlib.pyplot as plt\n","from PIL import Image"],"metadata":{"id":"-oeZX5Ts1rTN","executionInfo":{"status":"ok","timestamp":1743419331427,"user_tz":-330,"elapsed":22648,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}}},"id":"-oeZX5Ts1rTN","execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Define transformations\n","class CocoTransform:\n","    def __call__(self, image, target):\n","        image = F.to_tensor(image)  # Convert PIL image to tensor\n","        return image, target"],"metadata":{"id":"wCB0bBWX1uWP","executionInfo":{"status":"ok","timestamp":1743419331527,"user_tz":-330,"elapsed":26,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}}},"id":"wCB0bBWX1uWP","execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Dataset class\n","def get_coco_dataset(img_dir, ann_file):\n","    return CocoDetection(\n","        root=img_dir,\n","        annFile=ann_file,\n","        transforms=CocoTransform()\n","    )\n","\n","# Load datasets\n","train_dataset = get_coco_dataset(\n","    img_dir=\"/content/gdrive/MyDrive/REVA/Capstone 1/Faster RCNN/train/images\",\n","    ann_file=\"/content/gdrive/MyDrive/REVA/Capstone 1/Faster RCNN/train/train_annotations.json\"\n",")\n","\n","\n","val_dataset = get_coco_dataset(\n","    img_dir=\"/content/gdrive/MyDrive/REVA/Capstone 1/Faster RCNN/val/images\",\n","    ann_file=\"/content/gdrive/MyDrive/REVA/Capstone 1/Faster RCNN/val/val_annotations.json\"\n",")\n","\n","\n","\n","# DataLoader\n","train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n","val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z0NjPb5t1uiT","executionInfo":{"status":"ok","timestamp":1743419335029,"user_tz":-330,"elapsed":3473,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"c63b2eea-c57d-4468-c308-c0fa8bc6dff0"},"id":"z0NjPb5t1uiT","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["loading annotations into memory...\n","Done (t=2.22s)\n","creating index...\n","index created!\n","loading annotations into memory...\n","Done (t=1.34s)\n","creating index...\n","index created!\n"]}]},{"cell_type":"code","source":["# Load Faster R-CNN with ResNet-50 backbone\n","def get_model(num_classes):\n","    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n","    in_features = model.roi_heads.box_predictor.cls_score.in_features\n","    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","    return model"],"metadata":{"id":"ql4sJzhb2Ag-","executionInfo":{"status":"ok","timestamp":1743419335142,"user_tz":-330,"elapsed":102,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}}},"id":"ql4sJzhb2Ag-","execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Initialize the model\n","num_classes = 5\n","model = get_model(num_classes)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4c41QP2W2BWm","executionInfo":{"status":"ok","timestamp":1743419337367,"user_tz":-330,"elapsed":2236,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"ab7e4e4d-0536-4f2b-de3c-954978b1cba6"},"id":"4c41QP2W2BWm","execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n","100%|██████████| 160M/160M [00:01<00:00, 138MB/s]\n"]}]},{"cell_type":"code","source":["# Move model to GPU if available\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","model.to(device)\n","\n","# Define optimizer and learning rate scheduler\n","params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n","lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"],"metadata":{"id":"xSTdQeLv2E_K","executionInfo":{"status":"ok","timestamp":1743419337484,"user_tz":-330,"elapsed":102,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}}},"id":"xSTdQeLv2E_K","execution_count":10,"outputs":[]},{"cell_type":"code","source":["def train_one_epoch(model, optimizer, data_loader, device, epoch):\n","    model.train()\n","    for images, targets in data_loader:\n","        images = [img.to(device) for img in images]\n","\n","        processed_targets = []\n","        valid_images = []\n","        for i, target in enumerate(targets):\n","            boxes = []\n","            labels = []\n","            for obj in target:\n","                bbox = obj[\"bbox\"]\n","                x, y, w, h = bbox\n","\n","                if w > 0 and h > 0:\n","                    boxes.append([x, y, x + w, y + h])\n","                    label = obj[\"category_id\"]\n","\n","                    # Correct label mapping for 5 classes (0, 1, 2, 3, 4)\n","                    if label in [0, 1, 2, 3, 4]:  # Ensure label is valid\n","                        labels.append(label)\n","                    else:\n","                        continue  # Skip objects with invalid labels\n","\n","            if boxes:\n","                processed_target = {\n","                    \"boxes\": torch.tensor(boxes, dtype=torch.float32).to(device),\n","                    \"labels\": torch.tensor(labels, dtype=torch.int64).to(device),\n","                }\n","                processed_targets.append(processed_target)\n","                valid_images.append(images[i])\n","\n","        if not processed_targets:\n","            continue\n","\n","        images = valid_images\n","\n","        # Perform the forward pass and compute losses\n","        loss_dict = model(images, processed_targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        # Zero the gradients and backpropagate\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","    print(f\"Epoch [{epoch}] Loss: {losses.item():.4f}\")\n"],"metadata":{"id":"AHlIPMFz2I_4","executionInfo":{"status":"ok","timestamp":1743419337606,"user_tz":-330,"elapsed":74,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}}},"id":"AHlIPMFz2I_4","execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    train_one_epoch(model, optimizer, train_loader, device, epoch)\n","    lr_scheduler.step()\n","\n","    # Save the model's state dictionary after every epoch\n","    model_path = f\"fasterrcnn_resnet50_epoch_{epoch + 1}.pth\"\n","    torch.save(model.state_dict(), model_path)\n","    print(f\"Model saved: {model_path}\")"],"metadata":{"id":"mM2RLM8-2Mp6"},"id":"mM2RLM8-2Mp6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as T\n","import torchvision\n","import cv2\n","import os\n","import json\n","import numpy as np\n","from PIL import Image\n","\n","# Define paths\n","model_path = \"/content/gdrive/MyDrive/REVA/Capstone 1/Faster RCNN/fasterrcnn_resnet50_epoch_6.pth\"\n","test_images_path = \"/content/gdrive/MyDrive/REVA/Capstone 1/NewTest310325/images\"\n","output_dir = \"/content/gdrive/MyDrive/REVA/Capstone 1/NewTest310325/TestAnnotationfinal\"\n","json_output_dir = os.path.join(output_dir, \"json_outputs\")\n","\n","# Create output directories if they don't exist\n","os.makedirs(output_dir, exist_ok=True)\n","os.makedirs(json_output_dir, exist_ok=True)\n","\n","# Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Define class names\n","class_names = {\n","    1: \"Switch\",\n","    2: \"Crossing\",\n","    3: \"Normal Signal\",\n","    4: \"B2B Signal\"\n","}\n","\n","# Load the Faster R-CNN model with the correct number of classes\n","num_classes = 5  # Background + 4 classes\n","model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n","\n","# Modify the classifier to match the number of classes\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n","\n","# Load trained weights\n","model.load_state_dict(torch.load(model_path, map_location=device))\n","model.to(device)\n","model.eval()\n","\n","# Define image transformation\n","transform = T.Compose([T.ToTensor()])\n","\n","# Function to draw bounding boxes with class names\n","def draw_boxes(image, boxes, labels, scores, threshold=0.5):\n","    for box, label, score in zip(boxes, labels, scores):\n","        if score >= threshold:\n","            x1, y1, x2, y2 = map(int, box)\n","            class_name = class_names.get(label, \"Unknown\")  # Get class name, default to \"Unknown\"\n","            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","            cv2.putText(image, f'{class_name}: {score:.2f}', (x1, y1 - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","    return image\n","\n","# Run inference on test images\n","for img_name in os.listdir(test_images_path):\n","    img_path = os.path.join(test_images_path, img_name)\n","    image = Image.open(img_path).convert(\"RGB\")\n","    img_tensor = transform(image).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        predictions = model(img_tensor)\n","\n","    # Extract bounding boxes, labels, and scores\n","    boxes = predictions[0]['boxes'].cpu().numpy()\n","    labels = predictions[0]['labels'].cpu().tolist()\n","    scores = predictions[0]['scores'].cpu().tolist()\n","\n","    # Convert image to OpenCV format\n","    img_cv = np.array(image)\n","    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR)\n","\n","    # Draw detected objects with class names\n","    img_annotated = draw_boxes(img_cv, boxes, labels, scores)\n","\n","    # Save the annotated image\n","    output_path = os.path.join(output_dir, img_name)\n","    cv2.imwrite(output_path, img_annotated)\n","\n","    # Save JSON output\n","    json_output = {\n","        \"image_name\": img_name,\n","        \"detections\": []\n","    }\n","\n","    for box, label, score in zip(boxes, labels, scores):\n","        if score >= 0.5:  # Apply confidence threshold\n","            json_output[\"detections\"].append({\n","                \"class_name\": class_names.get(label, \"Unknown\"),\n","                \"bounding_box\": [int(box[0]), int(box[1]), int(box[2]), int(box[3])],\n","                \"confidence\": round(score, 2)\n","            })\n","\n","    json_path = os.path.join(json_output_dir, img_name.replace(\".jpg\", \".json\"))\n","    with open(json_path, \"w\") as f:\n","        json.dump(json_output, f, indent=4)\n","\n","print(\"Inference complete. Annotated images and JSON outputs saved at:\", output_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCWdXU1GBc5M","executionInfo":{"status":"ok","timestamp":1743420150696,"user_tz":-330,"elapsed":87993,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"0816230f-ef1d-4a7f-d4fa-825336e11857"},"id":"JCWdXU1GBc5M","execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:01<00:00, 76.9MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Inference complete. Annotated images and JSON outputs saved at: /content/gdrive/MyDrive/REVA/Capstone 1/NewTest310325/TestAnnotationfinal\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import numpy as np\n","import pandas as pd\n","from collections import defaultdict\n","\n","# Define mapping from predicted class names to category IDs\n","class_name_to_category_id = {\n","    \"Switch\": 1,\n","    \"Crossing\": 2,\n","    \"Normal Signal\": 3,\n","    \"B2B Signal\": 4\n","}\n","\n","category_id_to_name = {v: k for k, v in class_name_to_category_id.items()}  # Reverse mapping\n","\n","# Load ground truth JSON (single file)\n","def load_ground_truth(ground_truth_path):\n","    with open(ground_truth_path, \"r\") as f:\n","        gt_data = json.load(f)\n","\n","    # Convert ground truth into a dictionary mapping image_name -> class count\n","    gt_dict = defaultdict(lambda: defaultdict(int))\n","    image_id_to_name = {img[\"id\"]: img[\"file_name\"] for img in gt_data[\"images\"]}\n","\n","    for obj in gt_data[\"annotations\"]:\n","        category_id = obj.get(\"category_id\")\n","        if category_id is None:\n","            continue\n","\n","        image_id = obj.get(\"image_id\")\n","        if image_id is None or image_id not in image_id_to_name:\n","            continue\n","\n","        image_name = image_id_to_name[image_id]\n","        gt_dict[image_name][category_id] += 1  # Increment class count\n","\n","    return gt_dict\n","\n","# Load predicted JSON files\n","def load_predictions(predicted_dir):\n","    pred_dict = defaultdict(lambda: defaultdict(int))\n","\n","    for pred_filename in os.listdir(predicted_dir):\n","        if not pred_filename.endswith(\".json\"):\n","            continue\n","\n","        pred_filepath = os.path.join(predicted_dir, pred_filename)\n","\n","        with open(pred_filepath, \"r\") as f:\n","            pred_data = json.load(f)\n","\n","        image_name = pred_data.get(\"image_name\")\n","        if not image_name:\n","            print(f\"Warning: Missing image_name in {pred_filename}\")\n","            continue\n","\n","        for obj in pred_data.get(\"detections\", []):\n","            class_name = obj.get(\"class_name\")\n","            if class_name in class_name_to_category_id:\n","                class_id = class_name_to_category_id[class_name]\n","                pred_dict[image_name][class_id] += 1  # Increment class count\n","\n","    return pred_dict\n","\n","# IoU Calculation Function\n","def calculate_iou(box1, box2):\n","    \"\"\"Compute IoU (Intersection over Union) between two bounding boxes.\"\"\"\n","    x1_inter = max(box1[0], box2[0])\n","    y1_inter = max(box1[1], box2[1])\n","    x2_inter = min(box1[0] + box1[2], box2[0] + box2[2])\n","    y2_inter = min(box1[1] + box1[3], box2[1] + box2[3])\n","\n","    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n","    box1_area = box1[2] * box1[3]\n","    box2_area = box2[2] * box2[3]\n","    union_area = box1_area + box2_area - inter_area\n","\n","    return inter_area / union_area if union_area > 0 else 0\n","\n","# Compute Precision, Recall, F1-score, and mAP\n","def compute_metrics(ground_truth_path, predicted_dir, iou_thresholds=[0.4, 0.5, 0.6, 0.7, 0.75]):\n","    gt_dict = load_ground_truth(ground_truth_path)\n","    pred_dict = load_predictions(predicted_dir)\n","\n","    results = {}\n","\n","    for iou_thresh in iou_thresholds:\n","        tp = defaultdict(int)  # True Positives\n","        fp = defaultdict(int)  # False Positives\n","        fn = defaultdict(int)  # False Negatives\n","        total_gt_boxes = defaultdict(int)\n","\n","        all_image_names = set(gt_dict.keys()).union(set(pred_dict.keys()))\n","\n","        for image_name in all_image_names:\n","            gt_per_class = gt_dict[image_name]\n","            pred_per_class = pred_dict[image_name]\n","\n","            for class_id in category_id_to_name.keys():\n","                total_gt_boxes[class_id] += gt_per_class.get(class_id, 0)\n","\n","                gt_count = gt_per_class.get(class_id, 0)\n","                pred_count = pred_per_class.get(class_id, 0)\n","\n","                if pred_count > 0 and gt_count > 0:\n","                    tp[class_id] += min(gt_count, pred_count)\n","                    fp[class_id] += max(0, pred_count - gt_count)\n","                    fn[class_id] += max(0, gt_count - pred_count)\n","                elif pred_count > 0 and gt_count == 0:\n","                    fp[class_id] += pred_count\n","                elif gt_count > 0 and pred_count == 0:\n","                    fn[class_id] += gt_count\n","\n","        # Compute Precision, Recall, F1-score\n","        precision = {}\n","        recall = {}\n","        f1_score = {}\n","\n","        for class_id in total_gt_boxes:\n","            tp_val = tp[class_id]\n","            fp_val = fp[class_id]\n","            fn_val = fn[class_id]\n","\n","            precision[class_id] = tp_val / (tp_val + fp_val) if (tp_val + fp_val) > 0 else 0\n","            recall[class_id] = tp_val / (tp_val + fn_val) if (tp_val + fn_val) > 0 else 0\n","            f1_score[class_id] = (\n","                2 * (precision[class_id] * recall[class_id]) / (precision[class_id] + recall[class_id])\n","                if (precision[class_id] + recall[class_id]) > 0\n","                else 0\n","            )\n","\n","        # Compute mAP\n","        mAP = sum(precision.values()) / len(precision) if precision else 0\n","\n","        results[iou_thresh] = {\n","            \"Precision\": precision,\n","            \"Recall\": recall,\n","            \"F1-score\": f1_score,\n","            \"mAP\": round(mAP, 3)\n","        }\n","\n","    return results\n","\n","# Generate CSV for object counts\n","def generate_comparison_csv(ground_truth_path, predicted_dir, output_csv):\n","    gt_dict = load_ground_truth(ground_truth_path)\n","    pred_dict = load_predictions(predicted_dir)\n","\n","    data_rows = []\n","\n","    all_image_names = set(gt_dict.keys()).union(set(pred_dict.keys()))\n","\n","    for image_name in sorted(all_image_names):\n","        row = {\"Image Name\": image_name}\n","\n","        for class_id, class_name in category_id_to_name.items():\n","            gt_count = gt_dict[image_name].get(class_id, 0)\n","            pred_count = pred_dict[image_name].get(class_id, 0)\n","            row[f\"GT_{class_name}\"] = gt_count\n","            row[f\"Pred_{class_name}\"] = pred_count\n","            row[f\"Diff_{class_name}\"] = pred_count - gt_count\n","\n","        data_rows.append(row)\n","\n","    df = pd.DataFrame(data_rows)\n","    df.to_csv(output_csv, index=False)\n","    print(f\"Comparison CSV saved at: {output_csv}\")\n","\n","# Define paths\n","ground_truth_json_path = \"/content/gdrive/MyDrive/REVA/Capstone 1/NewTest310325/latest310325.json\"\n","predicted_json_dir = \"/content/gdrive/MyDrive/REVA/Capstone 1/NewTest310325/TestAnnotationfinal/json_outputs\"\n","output_csv_path = \"/content/gdrive/MyDrive/REVA/Capstone 1/NewTest310325/object_count_comparison.csv\"\n","\n","# Run CSV generation\n","generate_comparison_csv(ground_truth_json_path, predicted_json_dir, output_csv_path)\n","\n","# Run evaluation metrics\n","evaluation_results = compute_metrics(ground_truth_json_path, predicted_json_dir)\n","\n","# Print results\n","for iou_thresh, metrics in evaluation_results.items():\n","    print(f\"\\nResults at IoU {iou_thresh}:\")\n","    print(f\"mAP: {metrics['mAP']}\")\n","    for class_id, prec in metrics[\"Precision\"].items():\n","        print(f\"Class {class_id}: Precision={prec:.3f}, Recall={metrics['Recall'][class_id]:.3f}, F1-score={metrics['F1-score'][class_id]:.3f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rrt40ftjj3_","executionInfo":{"status":"ok","timestamp":1743420315317,"user_tz":-330,"elapsed":751,"user":{"displayName":"ravichandran r","userId":"10352585034039134331"}},"outputId":"21a53609-f5b5-4a77-e908-435c1223a2d2"},"id":"4rrt40ftjj3_","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Comparison CSV saved at: /content/gdrive/MyDrive/REVA/Capstone 1/NewTest310325/object_count_comparison.csv\n","\n","Results at IoU 0.4:\n","mAP: 0.997\n","Class 1: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 2: Precision=1.000, Recall=0.882, F1-score=0.938\n","Class 3: Precision=0.989, Recall=0.989, F1-score=0.989\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.5:\n","mAP: 0.997\n","Class 1: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 2: Precision=1.000, Recall=0.882, F1-score=0.938\n","Class 3: Precision=0.989, Recall=0.989, F1-score=0.989\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.6:\n","mAP: 0.997\n","Class 1: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 2: Precision=1.000, Recall=0.882, F1-score=0.938\n","Class 3: Precision=0.989, Recall=0.989, F1-score=0.989\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.7:\n","mAP: 0.997\n","Class 1: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 2: Precision=1.000, Recall=0.882, F1-score=0.938\n","Class 3: Precision=0.989, Recall=0.989, F1-score=0.989\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n","\n","Results at IoU 0.75:\n","mAP: 0.997\n","Class 1: Precision=1.000, Recall=1.000, F1-score=1.000\n","Class 2: Precision=1.000, Recall=0.882, F1-score=0.938\n","Class 3: Precision=0.989, Recall=0.989, F1-score=0.989\n","Class 4: Precision=1.000, Recall=1.000, F1-score=1.000\n"]}]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":6743749,"sourceId":10856940,"sourceType":"datasetVersion"},{"datasetId":6743774,"sourceId":10856969,"sourceType":"datasetVersion"}],"dockerImageVersionId":30822,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":15185.458805,"end_time":"2025-02-27T17:52:02.325718","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-27T13:38:56.866913","version":"2.6.0"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}